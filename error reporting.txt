Traceback (most recent call last):
  File "/cow02/rudenko/colowils/LLMExp/LLM-Exp/Pipeline Tests/evaltest.py", line 32, in <module>
    prediction = get_prediction(tokenized_question)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cow02/rudenko/colowils/LLMExp/LLM-Exp/Pipeline Tests/evaltest.py", line 24, in get_prediction
    inputs = tokenizer(tokenized_question, return_tensors="pt")
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cow02/rudenko/colowils/Miniconda3/envs/LLM/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2577, in __call__
    encodings = self._call_one(text=text, text_pair=text_pair, **all_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/cow02/rudenko/colowils/Miniconda3/envs/LLM/lib/python3.11/site-packages/transformers/tokenization_utils_base.py", line 2635, in _call_one
    raise ValueError(
ValueError: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).